{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam/Project -- Applied Machine Learning (CNN Portion)\n",
    "\n",
    "Josh Gregory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "For the specific convolutional neural network (CNN) architecture, I'm going to implement AlexNet from scratch in TensorFlow. [AlexNet](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) is a classic CNN architecture, designed by Alex Krizhevsy, Ilya Sutskever, and Geoffrey Hinton (now a Nobel Laureate). It was originally trained on the ImageNet datset, but has been lauded by many for uses in a variety of fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm running this notebook on my laptop, which has a discrete NVIDIA GPU. Let's make sure TensorFlow can see it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_images(data_directory):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for color in ['red', 'yellow', 'green']:\n",
    "        color_path = os.path.join(data_directory, color)\n",
    "\n",
    "        # Get all files in color directory\n",
    "\n",
    "        for file in os.listdir(color_path):\n",
    "            img_path = os.path.join(color_path, file)\n",
    "                \n",
    "            # Read in image\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            image_crop = np.copy(img)\n",
    "            row_crop = 7\n",
    "            col_crop = 8\n",
    "            image_crop = img[row_crop:-row_crop, col_crop:-col_crop, :]\n",
    "\n",
    "            img_resized = cv2.resize(image_crop, (32, 32))\n",
    "\n",
    "            # Resize image\n",
    "            # img_resized = transform.resize(img, (32, 32))\n",
    "\n",
    "            # Flatten image\n",
    "            flat_features = img_resized.flatten()\n",
    "            features.append(flat_features)\n",
    "\n",
    "            # Append the label as well\n",
    "            labels.append(color)\n",
    "\n",
    "    features = np.array(features)\n",
    "\n",
    "    # Convert strings of colors to integer values\n",
    "    light_dict = {'red': 0, 'yellow': 1, 'green': 2}\n",
    "    labels = np.array([light_dict[label] for label in labels])\n",
    "    features, labels = shuffle(features, labels, random_state=42)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cnn(input_shape=(32, 32, 3), num_classes=3):\n",
    "    model = models.Sequential([\n",
    "        # First convolutional layer\n",
    "        layers.Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='same', data_format='channels_last', name='conv_1', activation='relu'\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "\n",
    "\n",
    "\n",
    "    # Data augmentation to prevent overfitting\n",
    "    data_augmentation = models.Sequential([\n",
    "        layers.RandomFlip('horizontal'),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ])\n",
    "\n",
    "    # Create base model without data autmentation\n",
    "    model = create_base_cnn()\n",
    "\n",
    "    model = models.Sequential([\n",
    "        data_augmentation,\n",
    "        model\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
